{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n",
      "torch.Size([2, 5])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
      "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675, 0.2970, 0.4033, 0.3287, 0.1493,\n",
      "         0.1993]])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
      "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Basic\n",
    "import torch\n",
    "\n",
    "# Create a Tensor array\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y) # numpy operation\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "x = torch.zeros([2,5]) # zero matrix of 2 rows, 5 cols (2 arrays of length 5)\n",
    "y = torch.rand([2,5]) # random matrix of 2 rows, 5 cols\n",
    "\n",
    "print(x.shape) # see dim\n",
    "print(y)\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "print(y.view([1,10])) # reshape dim !(in-place)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Set up datasets ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# Retrieve training and testing data, download and transform into Tensor \n",
    "# param(file loc, train, download, transform)\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "# Load data as Torch object, helps iterate thru data\n",
    "\n",
    "# batch_size = gradient descent (optimization algorithm), controls the number of\n",
    "# training samples to work through before the modelâ€™s internal parameters are updated\n",
    "# shuffle = allows for better generalization principle\n",
    "\n",
    "# Within the dataset, feed 10 items at a time to the model, the model optimizes at each succession\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 3, 0, 2, 0, 4, 7, 6, 2, 0])]\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "# View a single data in matrix form\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    \n",
    "x, y = data[0][0], data[1][0] # access data matrix\n",
    "\n",
    "# ASSUMPTION: \n",
    "# x: compositions of images' pixels\n",
    "# y: values predicted, result of graphing x\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a single data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.87\n",
      "1: 11.24\n",
      "2: 9.93\n",
      "3: 10.22\n",
      "4: 9.74\n",
      "5: 9.04\n",
      "6: 9.86\n",
      "7: 10.44\n",
      "8: 9.75\n",
      "9: 9.92\n"
     ]
    }
   ],
   "source": [
    "# When inputing data into the neural network, be mindful of batch size, shuffle,\n",
    "# balance\n",
    "\n",
    "# Balance: When there are even distribution of values\n",
    "# In a dataset where 60% of the values are 3's, and 40% are #1-9, it is not balanced.\n",
    "# To alleviate imbalanced dataset, modify weights of specific classes when calculating\n",
    "# loss.\n",
    "\n",
    "# Confirm a dataset is balanced\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100:.2f}\")\n",
    "    \n",
    "# Since all values have very similar %, safe to assume it's balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Build Neural Network ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn # OOP in PyTorch\n",
    "import torch.nn.functional as F # Functions in PyTorch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # run init from parent class (nn.Module)\n",
    "        \n",
    "        # Define (3) fully-connected layers to nn\n",
    "        # self.fc1 = nn.Linear(input, output)\n",
    "        self.fc1 = nn.Linear(784, 64) # input: 784 from flatten 28x28 images\n",
    "                                      # output: 64 neurons in this hidden layers\n",
    "        self.fc2 = nn.Linear(64, 64) # input: 64 from fc1 output\n",
    "                                     # output: 64 neurons in this hidden layers\n",
    "        self.fc3 = nn.Linear(64, 64) # input: 64 from fc2 output\n",
    "                                     # output: 64 neurons in this hidden layers\n",
    "        self.fc4 = nn.Linear(64, 10) # input: 64 from fc3 output\n",
    "                                     # output: 10 classes from the MNIST #0-9\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # F.relu = activation fxn (rectified linear unit)\n",
    "        x = F.relu(self.fc1(x)) # activate the entire layer 1 \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1) \n",
    "            \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3287, -2.3579, -2.3603, -2.2117, -2.3223, -2.3536, -2.2444, -2.2307,\n",
      "         -2.3177, -2.3124]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test nn\n",
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28) # -1 = data of any size\n",
    "output = net(X)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Training models ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0123, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0181, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Loss (MSE): margin of error (try to minimize this value / increase confident interval)\n",
    "# - if predictions deviates a lot from actual results, loss fxn will return a large number\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# par1: adjustable variables in the model\n",
    "# par2: learning rate (also 1e-03, get by trial&error) --> gradient descent hops\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "\n",
    "# Epoch: full iteration through the entire data\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # Data is a \"Batch\" of featuresets and labels\n",
    "        X, y = data\n",
    "        \n",
    "        # print(X[0]) # rows of pixels making up an image (needs to be flatten)\n",
    "        # print(y[0]) # result of graphing X[0]\n",
    "        \n",
    "        net.zero_grad() # before passing data to NN, set up (reset) zero gradient \n",
    "        output = net(X.view(-1, 28*28)) # -1 replacable with any other batch size\n",
    "        \n",
    "        # If dataset is a scalar, use nll_loss; elif is a one-hot vector, use MSE\n",
    "        # One-hot encoding: description of an input\n",
    "        # Allows computer to understand input + human understand to output\n",
    "        # Length of each OHVector = # of categories (i.e. classifying dogs and cats yields [x, x])\n",
    "        loss = F.nll_loss(output, y) \n",
    "        loss.backward()\n",
    "        optimizer.step() # auto adjust weights\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.977\n"
     ]
    }
   ],
   "source": [
    "# Check for the goodness of the network (*note: high accuracy != best)\n",
    "# It's less likely to achieve high acc. on real data\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tVal = X[9]\n",
    "plt.imshow(tVal.view(28, 28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(tVal.view(-1, 784))[0])) # verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
