{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.,  3.])\n",
      "torch.Size([2, 5])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
      "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675, 0.2970, 0.4033, 0.3287, 0.1493,\n",
      "         0.1993]])\n",
      "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
      "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a Tensor array\n",
    "x = torch.Tensor([5,3])\n",
    "y = torch.Tensor([2,1])\n",
    "\n",
    "print(x*y) # numpy operation\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "x = torch.zeros([2,5]) # zero matrix of 2 rows, 5 cols (2 arrays of length 5)\n",
    "y = torch.rand([2,5]) # random matrix of 2 rows, 5 cols\n",
    "\n",
    "print(x.shape) # see dim\n",
    "print(y)\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "print(y.view([1,10])) # reshape dim !(in-place)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:01, 6840213.83it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 117009.95it/s]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 1713579.96it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 42880.53it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Retrieve training and testing data, download and transform into Tensor \n",
    "# param(file loc, train, download, transform)\n",
    "train = datasets.MNIST(\"\", train=True, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as Torch object, helps iterate thru data\n",
    "\n",
    "# batch_size = gradient descent (optimization algorithm), controls the number of\n",
    "# training samples to work through before the modelâ€™s internal parameters are updated\n",
    "# shuffle = allows for better generalization principle\n",
    "\n",
    "# Within the dataset, feed 10 items at a time to the model, the model optimizes at each succession\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 2, 4, 8, 5, 0, 2, 3, 3, 7])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0] # access data matrix\n",
    "\n",
    "# ASSUMPTION: \n",
    "# x: composition of each pixel (makes up an image of the 1st value in y)\n",
    "# y: value appearances in this particular data\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "plt.imshow(data[0][0].view(28, 28))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
      "0: 9.87\n",
      "1: 11.24\n",
      "2: 9.93\n",
      "3: 10.22\n",
      "4: 9.74\n",
      "5: 9.04\n",
      "6: 9.86\n",
      "7: 10.44\n",
      "8: 9.75\n",
      "9: 9.92\n"
     ]
    }
   ],
   "source": [
    "# When inputing data into the neural network, be mindful of batch size, shuffle,\n",
    "# balance\n",
    "\n",
    "# Balance: When there are even distribution of values\n",
    "# In a dataset where 60% of the values are 3's, and 40% are #1-9, it is not balanced.\n",
    "# To alleviate imbalanced dataset, modify weights of specific classes when calculating\n",
    "# loss.\n",
    "\n",
    "# Confirm a dataset is balanced\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "        \n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100:.2f}\")\n",
    "    \n",
    "# Since all values have very similar %, safe to assume it's balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
