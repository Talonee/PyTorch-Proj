{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "f1L2v-SBGC6I",
        "colab_type": "code",
        "outputId": "8375aac0-bf8c-4844-8322-8729b9ef72fe",
        "colab": {}
      },
      "source": [
        "# PyTorch Basic\n",
        "import torch\n",
        "\n",
        "# Create a Tensor array\n",
        "x = torch.Tensor([5,3])\n",
        "y = torch.Tensor([2,1])\n",
        "\n",
        "print(x*y) # numpy operation\n",
        "\n",
        "'''\n",
        "'''\n",
        "\n",
        "x = torch.zeros([2,5]) # zero matrix of 2 rows, 5 cols (2 arrays of length 5)\n",
        "y = torch.rand([2,5]) # random matrix of 2 rows, 5 cols\n",
        "\n",
        "print(x.shape) # see dim\n",
        "print(y)\n",
        "\n",
        "'''\n",
        "'''\n",
        "\n",
        "print(y.view([1,10])) # reshape dim !(in-place)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10.,  3.])\n",
            "torch.Size([2, 5])\n",
            "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
            "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n",
            "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675, 0.2970, 0.4033, 0.3287, 0.1493,\n",
            "         0.1993]])\n",
            "tensor([[0.2541, 0.4421, 0.6964, 0.1062, 0.8675],\n",
            "        [0.2970, 0.4033, 0.3287, 0.1493, 0.1993]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqG1IP4tGC6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Set up datasets ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5DANogpGC6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Retrieve training and testing data, download and transform into Tensor \n",
        "# param(file loc, train, download, transform)\n",
        "train = datasets.MNIST(\"\", train=True, download=True,\n",
        "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "test = datasets.MNIST(\"\", train=False, download=True,\n",
        "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "\n",
        "# Load data as Torch object, helps iterate thru data\n",
        "\n",
        "# batch_size = gradient descent (optimization algorithm), controls the number of\n",
        "# training samples to work through before the model’s internal parameters are updated\n",
        "# shuffle = allows for better generalization principle\n",
        "\n",
        "# Within the dataset, feed 10 items at a time to the model, the model optimizes at each succession\n",
        "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "yq9M1UhMGC6U",
        "colab_type": "code",
        "outputId": "09b8af0f-81a2-40ed-e39e-be2f511e4099",
        "colab": {}
      },
      "source": [
        "# View a single data in matrix form\n",
        "for data in trainset:\n",
        "    print(data)\n",
        "    break\n",
        "    \n",
        "x, y = data[0][0], data[1][0] # access data matrix\n",
        "\n",
        "# ASSUMPTION: \n",
        "# x: compositions of images' pixels\n",
        "# y: values predicted, result of graphing x\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([2, 3, 0, 2, 0, 4, 7, 6, 2, 0])]\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "A9wUrCVfGC6X",
        "colab_type": "code",
        "outputId": "9739c5f1-b1af-48c9-8437-f270e24d126e",
        "colab": {}
      },
      "source": [
        "# Plot a single data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(data[0][0].shape)\n",
        "plt.imshow(data[0][0].view(28, 28))\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "W1prI6f8GC6a",
        "colab_type": "code",
        "outputId": "45a3f146-c9fc-429e-8e0c-0c54a14974c6",
        "colab": {}
      },
      "source": [
        "# When inputing data into the neural network, be mindful of batch size, shuffle,\n",
        "# balance\n",
        "\n",
        "# Balance: When there are even distribution of values\n",
        "# In a dataset where 60% of the values are 3's, and 40% are #1-9, it is not balanced.\n",
        "# To alleviate imbalanced dataset, modify weights of specific classes when calculating\n",
        "# loss.\n",
        "\n",
        "# Confirm a dataset is balanced\n",
        "total = 0\n",
        "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
        "\n",
        "for data in trainset:\n",
        "    Xs, ys = data\n",
        "    for y in ys:\n",
        "        counter_dict[int(y)] += 1\n",
        "        total += 1\n",
        "        \n",
        "print(counter_dict)\n",
        "\n",
        "for i in counter_dict:\n",
        "    print(f\"{i}: {counter_dict[i]/total*100:.2f}\")\n",
        "    \n",
        "# Since all values have very similar %, safe to assume it's balanced."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n",
            "0: 9.87\n",
            "1: 11.24\n",
            "2: 9.93\n",
            "3: 10.22\n",
            "4: 9.74\n",
            "5: 9.04\n",
            "6: 9.86\n",
            "7: 10.44\n",
            "8: 9.75\n",
            "9: 9.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG49anOLGC6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Build Neural Network ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO-RS6D8GC6f",
        "colab_type": "code",
        "outputId": "cce8da2c-09b6-4663-dbd7-e70d77589a37",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn # OOP in PyTorch\n",
        "import torch.nn.functional as F # Functions in PyTorch\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # run init from parent class (nn.Module)\n",
        "        \n",
        "        # Define (3) fully-connected layers to nn\n",
        "        # self.fc1 = nn.Linear(input, output)\n",
        "        self.fc1 = nn.Linear(784, 64) # input: 784 from flatten 28x28 images\n",
        "                                      # output: 64 neurons in this hidden layers\n",
        "        self.fc2 = nn.Linear(64, 64) # input: 64 from fc1 output\n",
        "                                     # output: 64 neurons in this hidden layers\n",
        "        self.fc3 = nn.Linear(64, 64) # input: 64 from fc2 output\n",
        "                                     # output: 64 neurons in this hidden layers\n",
        "        self.fc4 = nn.Linear(64, 10) # input: 64 from fc3 output\n",
        "                                     # output: 10 classes from the MNIST #0-9\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # F.relu = activation fxn (rectified linear unit)\n",
        "        x = F.relu(self.fc1(x)) # activate the entire layer 1 \n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1) \n",
        "            \n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "cmAe201nGC6i",
        "colab_type": "code",
        "outputId": "5228f173-9768-4700-bd23-f1578fa184c0",
        "colab": {}
      },
      "source": [
        "# Test nn\n",
        "X = torch.rand((28,28))\n",
        "X = X.view(-1, 28*28) # -1 = data of any size\n",
        "output = net(X)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.3287, -2.3579, -2.3603, -2.2117, -2.3223, -2.3536, -2.2444, -2.2307,\n",
            "         -2.3177, -2.3124]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzU6KedGC6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Training models ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04SwVtznGC6m",
        "colab_type": "code",
        "outputId": "977798ca-08fb-4039-a815-74b3be8a5659",
        "colab": {}
      },
      "source": [
        "# Loss (MSE): margin of error (try to minimize this value / increase confident interval)\n",
        "# - if predictions deviates a lot from actual results, loss fxn will return a large number\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# par1: adjustable variables in the model\n",
        "# par2: learning rate (also 1e-03, get by trial&error) --> gradient descent hops\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
        "\n",
        "# Epoch: full iteration through the entire data\n",
        "EPOCHS = 3\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for data in trainset:\n",
        "        # Data is a \"Batch\" of featuresets and labels\n",
        "        X, y = data\n",
        "        \n",
        "        # print(X[0]) # rows of pixels making up an image (needs to be flatten)\n",
        "        # print(y[0]) # result of graphing X[0]\n",
        "        \n",
        "        net.zero_grad() # before passing data to NN, set up (reset) zero gradient \n",
        "        output = net(X.view(-1, 28*28)) # -1 replacable with any other batch size\n",
        "        \n",
        "        # If dataset is a scalar, use nll_loss; elif is a one-hot vector, use MSE\n",
        "        # One-hot encoding: description of an input\n",
        "        # Allows computer to understand input + human understand to output\n",
        "        # Length of each OHVector = # of categories (i.e. classifying dogs and cats yields [x, x])\n",
        "        loss = F.nll_loss(output, y) \n",
        "        loss.backward()\n",
        "        optimizer.step() # auto adjust weights\n",
        "    print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0123, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0134, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0181, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r96VMAPdGC6p",
        "colab_type": "code",
        "outputId": "3a4f5f38-1407-4cbf-ea9c-0d3a7cc810f8",
        "colab": {}
      },
      "source": [
        "# Check for the goodness of the network (*note: high accuracy != best)\n",
        "# It's less likely to achieve high acc. on real data\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in trainset:\n",
        "        X, y = data\n",
        "        output = net(X.view(-1, 784))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "print(\"Accuracy: \", round(correct/total, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6JFEcieGC6r",
        "colab_type": "code",
        "outputId": "47dea9f4-79cf-438d-f9aa-11d9cf2481c7",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "tVal = X[9]\n",
        "plt.imshow(tVal.view(28, 28))\n",
        "plt.show()\n",
        "print(torch.argmax(net(tVal.view(-1, 784))[0])) # verify"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypjBkO_pGC6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Convolutional NN ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV_uX_ilGC6v",
        "colab_type": "code",
        "outputId": "aef0ffac-55ce-4bb0-ccb9-b1ef2a44b666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "REBUILD_DATA = False\n",
        "\n",
        "if torch.cuda.is_available(): # check for GPU (Google Colab)\n",
        "    device = torch.device(\"cuda:0\") # choose GPU if more than one\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "class DogsVSCats():\n",
        "    IMG_SIZE = 50 # make uniform images of 50x50\n",
        "    CATS = \"PetImages/Cat\"\n",
        "    DOGS = \"PetImages/Dog\"\n",
        "    LABELS = {CATS: 0, DOGS: 1}\n",
        "    training_data = []\n",
        "    catcount = 0\n",
        "    dogcount = 0\n",
        "    \n",
        "    def make_training_data(self):\n",
        "        for label in self.LABELS:\n",
        "            print(label)\n",
        "            for f in tqdm(os.listdir(label)): # for each img_file in the folder\n",
        "                try:\n",
        "                    path = os.path.join(label, f)\n",
        "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # turn grayscale\n",
        "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) # resize\n",
        "                    \n",
        "                    # Associate each image with a label\n",
        "                    # np.eye(x) creates an identity matrix of size x, ([1,0], [0,1]) \n",
        "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
        "\n",
        "                    if label == self.CATS:\n",
        "                        self.catcount += 1\n",
        "                    elif label == self.DOGS:\n",
        "                        self.dogcount += 1\n",
        "                except Exception as e:\n",
        "                    # print(str(e))\n",
        "                    pass\n",
        "        np.random.shuffle(self.training_data)\n",
        "        np.save(\"training_data.npy\", self.training_data)\n",
        "        \n",
        "        print(\"Cats: \", self.catcount)\n",
        "        print(\"Dogs: \", self.dogcount)\n",
        "        \n",
        "if REBUILD_DATA:\n",
        "    dogsvcats = DogsVSCats()\n",
        "    dogsvcats.make_training_data()\n",
        "    \n",
        "training_data = np.load(\"training_data.npy\", allow_pickle=True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXw5CFN6GC6x",
        "colab_type": "code",
        "outputId": "eb5d6203-f290-40fe-8fd2-6491749581a9",
        "colab": {}
      },
      "source": [
        "print(training_data[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[153, 154, 150, ..., 163, 141, 161],\n",
            "       [149, 148, 155, ..., 155, 161, 124],\n",
            "       [153, 151, 150, ..., 154, 152, 156],\n",
            "       ...,\n",
            "       [139, 158, 130, ..., 115, 112, 110],\n",
            "       [148, 121, 106, ..., 100, 109, 100],\n",
            "       [135, 126, 125, ..., 129, 126, 131]], dtype=uint8)\n",
            " array([0., 1.])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5kuRERiGC60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(training_data[1][0], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdLYu5pwGC62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Training Covnet ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZhmUbCKGC64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Create 2-D conv layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5) # (input, output, kernel size)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
        "\n",
        "        # Flatten images into linear fc\n",
        "        x = torch.randn(50, 50).view(-1, 1, 50, 50)\n",
        "        self._to_linear = None\n",
        "        self.convs(x)\n",
        "        \n",
        "        # Create fully-connected layers\n",
        "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "    # Run this fxn with random data (x) to retrieve an input (to-linear),\n",
        "    # input is needed for the first fc layer\n",
        "    def convs(self, x): # similar to forward()\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))\n",
        "\n",
        "        if self._to_linear is None:\n",
        "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
        "            \n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.convs(x) # pass through conv layers\n",
        "        x = x.view(-1, self._to_linear) # flatten\n",
        "        x = F.relu(self.fc1(x)) # pass through 1st fully-connected layer\n",
        "        x = self.fc2(x) # bc this is the output layer, no activation\n",
        "        \n",
        "        return F.softmax(x, dim=1) # activation fxn\n",
        "    \n",
        "net = Net().to(device) # moves the entire NN to the GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-tYDNl7GC66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
        "X = X/255.0 # scale img pixel values to 0 and 1, original was 0-255 bc of colors\n",
        "y = torch.Tensor([i[1] for i in training_data])\n",
        "\n",
        "VAL_PCT = 0.1 # target to test 10% of our dataset\n",
        "val_size = int(len(X)*VAL_PCT)\n",
        "\n",
        "train_X = X[:-val_size]\n",
        "train_y = y[:-val_size]\n",
        "\n",
        "test_X = X[-val_size:]\n",
        "test_y = y[-val_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "KvrYzjIdGC7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Begin training\n",
        "BATCH_SIZE = 100 # lower value if encounter memory error\n",
        "EPOCHS = 10\n",
        "\n",
        "def train(net):    \n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        # tqdm is a progress bar\n",
        "        for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # range(start, end, step)\n",
        "            # print(i, i + BATCH_SIZE) # see each batch at their index in the dataset\n",
        "            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
        "            batch_y = train_y[i:i+BATCH_SIZE]\n",
        "            \n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            # Before fitment and optimization, need to zero the gradient\n",
        "            net.zero_grad()\n",
        "            outputs = net(batch_X)\n",
        "            loss = loss_function(outputs, batch_y) # calc loss based on output\n",
        "            loss.backward()\n",
        "            optimizer.step() # update\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "def test(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(test_X))):\n",
        "            real_class = torch.argmax(test_y[i]).to(device)\n",
        "            net_out = net(test_X[i].view(-1,1,50,50).to(device))[0]\n",
        "            predicted_class = torch.argmax(net_out)\n",
        "            if predicted_class == real_class:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    print(\"Accuracy:\", round(correct/total, 3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNPDfInBM7jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9b1c353a-0118-4198-b69a-efb54aa649e4"
      },
      "source": [
        "train(net)\n",
        "test(net)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 104.63it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 107.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0. Loss: 0.15110130608081818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.35it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 108.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1. Loss: 0.1355632245540619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.35it/s]\n",
            "  5%|▌         | 12/225 [00:00<00:01, 110.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2. Loss: 0.12759986519813538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.59it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 109.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3. Loss: 0.12288336455821991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.87it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:02, 101.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4. Loss: 0.11427795886993408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 104.87it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:02, 104.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5. Loss: 0.10694730281829834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.12it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 107.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6. Loss: 0.10645871609449387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.20it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 108.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7. Loss: 0.10315454006195068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.12it/s]\n",
            "  5%|▍         | 11/225 [00:00<00:01, 107.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8. Loss: 0.09003334492444992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:02<00:00, 105.23it/s]\n",
            "  7%|▋         | 167/2494 [00:00<00:01, 1663.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9. Loss: 0.0911555290222168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2494/2494 [00:01<00:00, 1623.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a11PBJWWhQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Model Analysis ########################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LszekvOpVXo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fwd_pass(X, y, train=False):\n",
        "    if train:\n",
        "        net.zero_grad()\n",
        "    outputs = net(X)\n",
        "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
        "    acc = matches.count(True)/len(matches)\n",
        "    loss = loss_function(outputs, y)\n",
        "\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return acc, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW8pM9MsWgR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "154be5d2-3372-4e5c-acab-019524817ca8"
      },
      "source": [
        "def test(size=32):\n",
        "    random_start = np.random.randint(len(test_X)-size)\n",
        "    X, y = test_X[random_start:random_start+size], test_y[random_start:random_start+size]\n",
        "    with torch.no_grad():\n",
        "        val_acc, val_loss = fwd_pass(X.view(-1,1,50,50).to(device), y.to(device))\n",
        "\n",
        "    return val_acc, val_loss\n",
        "\n",
        "val_acc, val_loss = test(size=32)\n",
        "print(val_acc, val_loss)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.71875 tensor(0.1912, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE5UIZjdZyOo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "79c590a7-3fc5-4144-df91-49610bc2449f"
      },
      "source": [
        "import time\n",
        "\n",
        "MODEL_NAME = f\"model - {int(time.time())}\"\n",
        "\n",
        "net = Net().to(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_function = nn.MSELoss()\n",
        "\n",
        "print(MODEL_NAME)\n",
        "\n",
        "def train():\n",
        "    BATCH_SIZE = 100\n",
        "    EPOCHS = 30\n",
        "\n",
        "    with open(\"model_30_epochs.log\", \"a\") as f:\n",
        "        for epoch in range(EPOCHS):\n",
        "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
        "                batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50).to(device)\n",
        "                batch_y = train_y[i:i+BATCH_SIZE].to(device)\n",
        "\n",
        "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
        "                if i % 50 == 0:\n",
        "                    val_acc, val_loss = test(size=100)\n",
        "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)}\\n\")\n",
        "\n",
        "train()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 4/225 [00:00<00:06, 36.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model - 1577688250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 225/225 [00:05<00:00, 39.00it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.65it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.45it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.41it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.72it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.91it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 37.83it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 37.63it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.14it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.66it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 39.35it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.44it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.43it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.62it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.43it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.32it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.80it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.08it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.40it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 37.97it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.69it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.36it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.15it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.52it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 37.99it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.64it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.84it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.52it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 39.23it/s]\n",
            "100%|██████████| 225/225 [00:05<00:00, 38.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHTWv-QbcfuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}